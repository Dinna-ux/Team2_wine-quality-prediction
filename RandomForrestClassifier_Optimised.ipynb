{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dependencies \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data from SQL databases for Red and White Wines\n",
    "# Connect to SQLite database and retrieve red wine data\n",
    "conn = sqlite3.connect('red_wine_quality.db')\n",
    "red_wine_df = pd.read_sql_query(\"SELECT * FROM red_wine_quality\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Connect to SQLite database and retrieve white wine data\n",
    "conn = sqlite3.connect('white_wine_quality.db')\n",
    "white_wine_df = pd.read_sql_query(\"SELECT * FROM white_wine_quality\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to Train, predict and extract the final metrics (Confusion matrix & Classification Report)\n",
    "def train_and_evaluate(df):\n",
    "    # Setting up a binary identifier for quality\n",
    "    df['quality'] = df['quality'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "\n",
    "    # Separating features and target\n",
    "    X = df.drop(['quality', 'type'], axis=1)\n",
    "    y = df['quality']\n",
    "\n",
    "    # Splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scaling the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Training initial model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_initial = model.predict(X_test)\n",
    "\n",
    "    # Evaluating initial model\n",
    "    conf_matrix_initial = confusion_matrix(y_test, y_pred_initial)\n",
    "    class_report_initial = classification_report(y_test, y_pred_initial, output_dict=True)\n",
    "    accuracy_initial = accuracy_score(y_test, y_pred_initial)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth': [4, 6, 8, 10, 12],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Training optimized model\n",
    "    best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred_optimized = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluating optimized model\n",
    "    conf_matrix_optimized = confusion_matrix(y_test, y_pred_optimized)\n",
    "    class_report_optimized = classification_report(y_test, y_pred_optimized, output_dict=True)\n",
    "    accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "\n",
    "    return {\n",
    "        'initial': {\n",
    "            'conf_matrix': conf_matrix_initial,\n",
    "            'class_report': class_report_initial,\n",
    "            'accuracy': accuracy_initial\n",
    "        },\n",
    "        'optimized': {\n",
    "            'conf_matrix': conf_matrix_optimized,\n",
    "            'class_report': class_report_optimized,\n",
    "            'accuracy': accuracy_optimized\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Function to extract and define which metrics are recorded\n",
    "def extract_metrics(conf_matrix, class_report, accuracy):\n",
    "    metrics = {\n",
    "        'Precision': class_report['weighted avg']['precision'],\n",
    "        'Recall': class_report['weighted avg']['recall'],\n",
    "        'F1-Score': class_report['weighted avg']['f1-score'],\n",
    "        'Support': class_report['weighted avg']['support'],\n",
    "        'Accuracy': accuracy,\n",
    "        'Predicted Positive Actual Positive': conf_matrix[1, 1],\n",
    "        'Predicted Positive Actual Negative': conf_matrix[0, 1],\n",
    "        'Predicted Negative Actual Positive': conf_matrix[1, 0],\n",
    "        'Predicted Negative Actual Negative': conf_matrix[0, 0]\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "250 fits failed out of a total of 750.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "175 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.88820772\n",
      " 0.88664522 0.88508272 0.88429841 0.88585784 0.88820772 0.88664522\n",
      " 0.88508272 0.88429841 0.88585784        nan        nan        nan\n",
      "        nan        nan 0.89523591 0.89211091 0.89367341 0.89289216\n",
      " 0.89289216 0.89523591 0.89211091 0.89367341 0.89289216 0.89289216\n",
      "        nan        nan        nan        nan        nan 0.89211397\n",
      " 0.89680147 0.89523591 0.89289216 0.89211091 0.89211397 0.89680147\n",
      " 0.89523591 0.89289216 0.89211091        nan        nan        nan\n",
      "        nan        nan 0.89836397 0.89914828 0.90071078 0.90070772\n",
      " 0.90227328 0.89836397 0.89914828 0.90071078 0.90070772 0.90227328\n",
      "        nan        nan        nan        nan        nan 0.90071385\n",
      " 0.90228248 0.90227328 0.90539828 0.90305453 0.90071385 0.90228248\n",
      " 0.90227328 0.90539828 0.90305453        nan        nan        nan\n",
      "        nan        nan 0.88507659 0.88507353 0.88663909 0.88663909\n",
      " 0.88820159 0.88507659 0.88507353 0.88663909 0.88663909 0.88820159\n",
      "        nan        nan        nan        nan        nan 0.88663909\n",
      " 0.89289216 0.89211091 0.89132966 0.89054841 0.88663909 0.89289216\n",
      " 0.89211091 0.89132966 0.89054841        nan        nan        nan\n",
      "        nan        nan 0.89523591 0.89211397 0.89211091 0.89054841\n",
      " 0.89054841 0.89523591 0.89211397 0.89211091 0.89054841 0.89054841\n",
      "        nan        nan        nan        nan        nan 0.89602022\n",
      " 0.89836091 0.90071078 0.89992647 0.90070772 0.89602022 0.89836091\n",
      " 0.90071078 0.89992647 0.90070772        nan        nan        nan\n",
      "        nan        nan 0.90539828 0.90696078 0.90539828 0.90618566\n",
      " 0.90462316 0.90539828 0.90696078 0.90539828 0.90618566 0.90462316]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "250 fits failed out of a total of 750.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "178 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\james\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.8095994\n",
      " 0.81189629 0.81164086 0.8106198  0.81062078 0.8095994  0.81189629\n",
      " 0.81164086 0.8106198  0.81062078        nan        nan        nan\n",
      "        nan        nan 0.83461015 0.83409929 0.83409897 0.83460884\n",
      " 0.83256672 0.83461015 0.83409929 0.83409897 0.83460884 0.83256672\n",
      "        nan        nan        nan        nan        nan 0.84736948\n",
      " 0.84890075 0.84839022 0.84813577 0.84890107 0.84736948 0.84890075\n",
      " 0.84839022 0.84813577 0.84890107        nan        nan        nan\n",
      "        nan        nan 0.85553698 0.85783225 0.86089445 0.86089511\n",
      " 0.86089413 0.85553698 0.85783225 0.86089445 0.86089511 0.86089413\n",
      "        nan        nan        nan        nan        nan 0.86446816\n",
      " 0.86829567 0.87033844 0.86855273 0.87008367 0.86446816 0.86829567\n",
      " 0.87033844 0.86855273 0.87008367        nan        nan        nan\n",
      "        nan        nan 0.81036405 0.81010862 0.80934234 0.81010797\n",
      " 0.80959777 0.81036405 0.81010862 0.80934234 0.81010797 0.80959777\n",
      "        nan        nan        nan        nan        nan 0.83103481\n",
      " 0.83129187 0.83078101 0.83027081 0.83078101 0.83103481 0.83129187\n",
      " 0.83078101 0.83027081 0.83078101        nan        nan        nan\n",
      "        nan        nan 0.84634842 0.84481781 0.84430663 0.84558312\n",
      " 0.84507226 0.84634842 0.84481781 0.84430663 0.84558312 0.84507226\n",
      "        nan        nan        nan        nan        nan 0.85834441\n",
      " 0.85809061 0.85808996 0.85961959 0.85834278 0.85834441 0.85809061\n",
      " 0.85808996 0.85961959 0.85834278        nan        nan        nan\n",
      "        nan        nan 0.86421567 0.8703404  0.86957314 0.8713595\n",
      " 0.86855208 0.86421567 0.8703404  0.86957314 0.8713595  0.86855208]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Process the Red and White Wine data\n",
    "\n",
    "# Process Red Wine\n",
    "red_wine_results = train_and_evaluate(red_wine_df)\n",
    "\n",
    "# Process White Wine\n",
    "white_wine_results = train_and_evaluate(white_wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Precision    Recall  F1-Score  Support  Accuracy  \\\n",
      "Red Wine Initial       0.891574  0.900000  0.892500    320.0  0.900000   \n",
      "Red Wine Optimized     0.902702  0.909375  0.901983    320.0  0.909375   \n",
      "White Wine Initial     0.888151  0.890816  0.884969    980.0  0.890816   \n",
      "White Wine Optimized   0.882145  0.885714  0.879978    980.0  0.885714   \n",
      "\n",
      "                      Predicted Positive Actual Positive  \\\n",
      "Red Wine Initial                                    24.0   \n",
      "Red Wine Optimized                                  25.0   \n",
      "White Wine Initial                                 145.0   \n",
      "White Wine Optimized                               144.0   \n",
      "\n",
      "                      Predicted Positive Actual Negative  \\\n",
      "Red Wine Initial                                     9.0   \n",
      "Red Wine Optimized                                   7.0   \n",
      "White Wine Initial                                  25.0   \n",
      "White Wine Optimized                                29.0   \n",
      "\n",
      "                      Predicted Negative Actual Positive  \\\n",
      "Red Wine Initial                                    23.0   \n",
      "Red Wine Optimized                                  22.0   \n",
      "White Wine Initial                                  82.0   \n",
      "White Wine Optimized                                83.0   \n",
      "\n",
      "                      Predicted Negative Actual Negative  \n",
      "Red Wine Initial                                   264.0  \n",
      "Red Wine Optimized                                 266.0  \n",
      "White Wine Initial                                 728.0  \n",
      "White Wine Optimized                               724.0  \n"
     ]
    }
   ],
   "source": [
    "#Creating a dataframe for the results\n",
    "# Extract metrics for initial and optimized models for red wine\n",
    "red_initial_metrics = extract_metrics(red_wine_results['initial']['conf_matrix'], red_wine_results['initial']['class_report'], red_wine_results['initial']['accuracy'])\n",
    "red_optimized_metrics = extract_metrics(red_wine_results['optimized']['conf_matrix'], red_wine_results['optimized']['class_report'], red_wine_results['optimized']['accuracy'])\n",
    "\n",
    "# Extract metrics for initial and optimized models for white wine\n",
    "white_initial_metrics = extract_metrics(white_wine_results['initial']['conf_matrix'], white_wine_results['initial']['class_report'], white_wine_results['initial']['accuracy'])\n",
    "white_optimized_metrics = extract_metrics(white_wine_results['optimized']['conf_matrix'], white_wine_results['optimized']['class_report'], white_wine_results['optimized']['accuracy'])\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Red Wine Initial': red_initial_metrics,\n",
    "    'Red Wine Optimized': red_optimized_metrics,\n",
    "    'White Wine Initial': white_initial_metrics,\n",
    "    'White Wine Optimized': white_optimized_metrics\n",
    "}).T\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('wine_quality_results_RFC.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
