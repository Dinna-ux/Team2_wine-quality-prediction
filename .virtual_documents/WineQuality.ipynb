import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import sklearn as sk
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression
import sqlite3
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer


# Loading red and white datasets
red_wine_df = pd.read_csv("./Resources/winequality-red.csv", delimiter=";")
white_wine_df = pd.read_csv("./Resources/winequality-white.csv", delimiter=";")

# Adding columns to distinguish between white and red wines
red_wine_df['type'] = 'Red'
white_wine_df['type'] = 'White'

# Combining the red and white DataFrames
wine_df = pd.concat([red_wine_df, white_wine_df])

# Creating SQLite database and saving the DataFrame
conn = sqlite3.connect('wine_quality.db')
wine_df.to_sql('wine_quality', conn, if_exists='replace', index=False)

# Retrieve the data from the database
query = "SELECT * FROM wine_quality"
wine_df = pd.read_sql_query(query, conn)

# Close the connection
conn.close()

print("Data has been successfully saved to wine_quality.db")


# Data cleaning, normalization, and standardization
# Drop any rows with missing values (if any)
wine_df.dropna(inplace=True)

# Separate features and target variable
X = wine_df.drop('quality', axis=1)
y = wine_df['quality']

# Encode the 'type' column using one-hot encoding.
column_transformer = ColumnTransformer(
    transformers=[
        ('onehot', OneHotEncoder(), ['type'])
    ],
    remainder='passthrough' #No changes to the remaining columns
)
X_transformed = column_transformer.fit_transform(X)

# Get feature names after transformation
feature_names = column_transformer.get_feature_names_out()

# Standardization and normalization of the features 
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_transformed)

#Scaled features back to DataFrame
X_scaled_df = pd.DataFrame(X_scaled, columns=feature_names)

# Scaled features back to a DataFrame for further processing 
X_scaled_df = pd.DataFrame(X_scaled, columns=feature_names)

# Add the type column back for filtering
X_scaled_df['quality'] = y.values

# Find the column names for the one-hot encoded types
type_red_col = [col for col in X_scaled_df.columns if 'type_Red' in col][0]
type_white_col = [col for col in X_scaled_df.columns if 'type_White' in col][0]

#Split the scaled features into white and red wine for visualisation
red_wine_df_scaled = X_scaled_df[X_scaled_df[type_red_col] == 1].drop([type_red_col, type_white_col], axis=1)
white_wine_df_scaled = X_scaled_df[X_scaled_df[type_white_col] == 1].drop([type_red_col, type_white_col], axis=1)


#Print red_wine data
red_wine_df.head()


#print white wine data
white_wine_df.head()


#describe the data frame
red_wine_df.describe()


#describe the data frame
white_wine_df.describe()


#Plot the data in a box plot
plt.figure(figsize=(30, 15))
sns.boxplot (data=red_wine_df)


#Plot the data in a box plot
plt.figure(figsize=(30, 15))
sns.boxplot (data=white_wine_df)


# Multivariate Analysis
plt.figure(figsize=(30, 15))
sns.pairplot(data=red_wine_df)
plt.show


# Multivariate Analysis
plt.figure(figsize=(30, 15))
sns.pairplot(data=white_wine_df)
plt.show



# Heatmap
numeric_red_wine_df = red_wine_df.select_dtypes(include=[np.number])
plt.figure(figsize=(20, 15))
sns.heatmap(numeric_red_wine_df.corr(), vmin=-1, vmax=1, cmap="coolwarm", annot=True)
plt.show()


import plotly.express as px

# Correlation between quality and red wine
correlation = red_wine_df.corr()['quality'].sort_values(ascending=False)
top_features = correlation.index[1:6] 

# Interactive bar plot for red wine
plot_red = px.bar(
    x=correlation[top_features],
    y=top_features,
    orientation='h',
    labels={'x': 'Correlation with Quality', 'y': 'Features'},
    title='Key Features Influencing the Quality of Red Wine',
    color=top_features,
    color_continuous_scale='Reds'
)

plot_red.update_layout(
    yaxis={'categoryorder': 'total ascending'}
)

# Show plot
plot_red.show()

#Correlation between white wine quality
correlation_white = white_wine_df.corr()['quality'].sort_values(ascending=False)
top_features_white = correlation_white.index[1:6]

# Interactive bar plot for white wine
plot_white = px.bar(
    x=correlation_white[top_features_white],
    y=top_features_white,
    orientation='h',
    labels={'x': 'Correlation with Quality', 'y': 'Features'},
    title='Key Features Influencing the Quality of White Wine',
    color=top_features_white,
    color_continuous_scale='Blues'
)

plot_white.update_layout(
    yaxis={'categoryorder': 'total ascending'}
)
# Show plot
plot_white.show()



#Comparative analysis between white and red wines
red_wine_df['type'] = 'Red'
white_wine_df['type'] = 'White'
wine_df = pd.concat([red_wine_df, white_wine_df])

#Alcohol vs Quality Scatter Plot Interactivity
fig = px.scatter(wine_df, x='alcohol', y='quality', color='type', 
                 title='Alcohol Content vs. Quality',
                 labels={'alcohol': 'Alcohol Content', 'quality': 'Quality'},
                 template='plotly_dark')

fig.show()


#Importing further libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix


#setting up a binary indentifier for quality, choosing 7 and above to determine a good quality wine
wine_df['quality'] = wine_df['quality'].apply(lambda x: 1 if x >= 7 else 0)
wine_df.head()


#Counting how many "good" wines
good_wines = wine_df[wine_df['quality'] == 1]

quality_counts = good_wines['quality'].count()
print(quality_counts)


#Separating the features from the target, target being wine quality (y), features being all other columns
#dropping wine type as this is not a distinguishing feature
X = wine_df.drop(['quality', 'type'], axis = 1)
y = wine_df['quality']


#splitting the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


#Scaling the features to make them standardised
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Training a Random Forrest Classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)


# Predictions from the test set
y_prediction = model.predict(X_test)

#Evaluating model effectiveness with confusion matrix and classification report
print(confusion_matrix(y_test, y_prediction))
print(classification_report(y_test, y_prediction))



