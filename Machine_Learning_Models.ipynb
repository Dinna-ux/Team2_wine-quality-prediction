{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18e2779-45c5-481b-a675-27c4a96c12cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d0b66c-9dd5-42ff-b369-151eca605dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to SQLite database and retrieve data\n",
    "conn = sqlite3.connect('wine_quality.db')\n",
    "query = \"SELECT * FROM wine_quality\"\n",
    "wine_df = pd.read_sql_query(query, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec55a6a3-ffb7-4a4f-ad1d-f60754858c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully retrieved from wine_quality.db\n"
     ]
    }
   ],
   "source": [
    "print(\"Data has been successfully retrieved from wine_quality.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb1963b-00be-4d34-90e9-b72d137ce3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality type  \n",
       "0      9.4        0  Red  \n",
       "1      9.8        0  Red  \n",
       "2      9.8        0  Red  \n",
       "3      9.8        0  Red  \n",
       "4      9.4        0  Red  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up a binary identifier for quality\n",
    "wine_df['quality'] = wine_df['quality'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a1d950-0977-4f80-a09b-8954a3e5a2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1277\n"
     ]
    }
   ],
   "source": [
    "# Count how many \"good\" wines\n",
    "good_wines = wine_df[wine_df['quality'] == 1]\n",
    "quality_counts = good_wines['quality'].count()\n",
    "print(quality_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604115c6-d0c8-4a7b-a40f-29f414ce34ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = wine_df.drop(['quality', 'type'], axis=1)\n",
    "y = wine_df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3fafa23-bc39-46f3-864e-a0ba0f7b5028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f424405-c22d-498f-9e89-c348ff31f828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "802af3e5-5110-40a8-b8e6-cb3571e97b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to evaluate and print model performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return classification_report(y_test, y_pred, output_dict=True), confusion_matrix(y_test, y_pred), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a04ce89-d970-454a-88f4-91b766933f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('Linear Discriminant Analysis', LinearDiscriminantAnalysis()),\n",
    "    ('Support Vector Machine', SVC(random_state=42)),\n",
    "    ('Decision Tree Classifier', DecisionTreeClassifier(random_state=42)),\n",
    "    ('Random Forest Classifier', RandomForestClassifier(random_state=42)),\n",
    "    ('Gradient Boosting Classifier', GradientBoostingClassifier(random_state=42)),\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=42)),\n",
    "    ('Bagging Classifier', BaggingClassifier(random_state=42)),\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),\n",
    "    ('Gaussian Naive Bayes', GaussianNB()),\n",
    "    ('Quadratic Discriminant Analysis', QuadraticDiscriminantAnalysis()),\n",
    "    ('Multilayer Perceptron', MLPClassifier(random_state=42)),\n",
    "    ('Ridge Classifier', RidgeClassifier(random_state=42)),\n",
    "    ('ExtraTrees Classifier', ExtraTreesClassifier(random_state=42)),\n",
    "    ('Isolation Forest', IsolationForest(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2dd749b-da58-4ba4-8317-4dcc9f4e84b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'Model', 'Precision', 'Recall', 'F1-Score', 'Support', 'Accuracy',\n",
    "    'Predicted Positive Actual Positive', 'Predicted Positive Actual Negative',\n",
    "    'Predicted Negative Actual Positive', 'Predicted Negative Actual Negative'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a5f85f1-9a41-4f48-bcf8-3e0e7f8ddb7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n",
      "Evaluating Linear Discriminant Analysis...\n",
      "Evaluating Support Vector Machine...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree Classifier...\n",
      "Evaluating Random Forest Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Gradient Boosting Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bagging Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating K-Nearest Neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Gaussian Naive Bayes...\n",
      "Evaluating Quadratic Discriminant Analysis...\n",
      "Evaluating Multilayer Perceptron...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Ridge Classifier...\n",
      "Evaluating ExtraTrees Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Isolation Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\morga\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\morga\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\morga\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\morga\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\morga\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_21476\\3830747791.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for name, model in models:\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    try:\n",
    "        if 'PCA' in name or 'K-Means' in name:\n",
    "            model.fit(X_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred = (y_pred > 0.5).astype(int) if 'PCA' in name else y_pred\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            report, cm, accuracy = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "        # Store the results in the DataFrame\n",
    "        results_df = results_df.append({\n",
    "            'Model': name,\n",
    "            'Precision': report['1']['precision'],\n",
    "            'Recall': report['1']['recall'],\n",
    "            'F1-Score': report['1']['f1-score'],\n",
    "            'Support': report['1']['support'],\n",
    "            'Accuracy': accuracy,\n",
    "            'Predicted Positive Actual Positive': cm[1, 1],\n",
    "            'Predicted Positive Actual Negative': cm[0, 1],\n",
    "            'Predicted Negative Actual Positive': cm[1, 0],\n",
    "            'Predicted Negative Actual Negative': cm[0, 0]\n",
    "        }, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to evaluate {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c2b57-2f0b-4cdb-ba1e-d94f5ec87789",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "THE BEST MODEL FOR WHITE WINE WAS FOUND TO BE RANDOMFOREST CLASSIFIER.\n",
    "\n",
    "THE BEST MODEL FOR RED WINE WAS FOUND TO BE THE EXTRATREESCLASSIFIER AND THE BAGGING CLASSIFIER DEPENDING ON IF RECALL IS MORE/LESS IMPORTANT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "751f5767-9ff7-40a8-8383-143587692c22",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "520/520 [==============================] - 2s 2ms/step - loss: 0.4053 - accuracy: 0.8126 - val_loss: 0.3667 - val_accuracy: 0.8292\n",
      "Epoch 2/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.3665 - accuracy: 0.8309 - val_loss: 0.3610 - val_accuracy: 0.8200\n",
      "Epoch 3/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8332 - val_loss: 0.3479 - val_accuracy: 0.8400\n",
      "Epoch 4/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.3474 - accuracy: 0.8368 - val_loss: 0.3463 - val_accuracy: 0.8315\n",
      "Epoch 5/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8422 - val_loss: 0.3453 - val_accuracy: 0.8338\n",
      "Epoch 6/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.3347 - accuracy: 0.8439 - val_loss: 0.3494 - val_accuracy: 0.8300\n",
      "Epoch 7/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8445 - val_loss: 0.3618 - val_accuracy: 0.8300\n",
      "Epoch 8/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.3255 - accuracy: 0.8515 - val_loss: 0.3409 - val_accuracy: 0.8469\n",
      "Epoch 9/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.3201 - accuracy: 0.8495 - val_loss: 0.3430 - val_accuracy: 0.8385\n",
      "Epoch 10/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.3147 - accuracy: 0.8563 - val_loss: 0.3404 - val_accuracy: 0.8408\n",
      "Epoch 11/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.3126 - accuracy: 0.8563 - val_loss: 0.3410 - val_accuracy: 0.8438\n",
      "Epoch 12/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.3057 - accuracy: 0.8607 - val_loss: 0.3373 - val_accuracy: 0.8408\n",
      "Epoch 13/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.3011 - accuracy: 0.8640 - val_loss: 0.3530 - val_accuracy: 0.8354\n",
      "Epoch 14/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.3005 - accuracy: 0.8659 - val_loss: 0.3400 - val_accuracy: 0.8408\n",
      "Epoch 15/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.2950 - accuracy: 0.8647 - val_loss: 0.3404 - val_accuracy: 0.8346\n",
      "Epoch 16/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2936 - accuracy: 0.8643 - val_loss: 0.3383 - val_accuracy: 0.8431\n",
      "Epoch 17/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2870 - accuracy: 0.8670 - val_loss: 0.3445 - val_accuracy: 0.8385\n",
      "Epoch 18/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2839 - accuracy: 0.8728 - val_loss: 0.3418 - val_accuracy: 0.8408\n",
      "Epoch 19/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.8732 - val_loss: 0.3388 - val_accuracy: 0.8438\n",
      "Epoch 20/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.2771 - accuracy: 0.8744 - val_loss: 0.3298 - val_accuracy: 0.8446\n",
      "Epoch 21/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2696 - accuracy: 0.8769 - val_loss: 0.3430 - val_accuracy: 0.8323\n",
      "Epoch 22/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2681 - accuracy: 0.8801 - val_loss: 0.3320 - val_accuracy: 0.8485\n",
      "Epoch 23/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.8840 - val_loss: 0.3330 - val_accuracy: 0.8462\n",
      "Epoch 24/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2601 - accuracy: 0.8871 - val_loss: 0.3452 - val_accuracy: 0.8454\n",
      "Epoch 25/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2558 - accuracy: 0.8820 - val_loss: 0.3363 - val_accuracy: 0.8492\n",
      "Epoch 26/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.8897 - val_loss: 0.3524 - val_accuracy: 0.8254\n",
      "Epoch 27/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.2480 - accuracy: 0.8913 - val_loss: 0.3347 - val_accuracy: 0.8500\n",
      "Epoch 28/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.8951 - val_loss: 0.3544 - val_accuracy: 0.8438\n",
      "Epoch 29/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2405 - accuracy: 0.8949 - val_loss: 0.3560 - val_accuracy: 0.8446\n",
      "Epoch 30/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.2410 - accuracy: 0.8909 - val_loss: 0.3376 - val_accuracy: 0.8492\n",
      "Epoch 31/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2319 - accuracy: 0.8984 - val_loss: 0.3615 - val_accuracy: 0.8523\n",
      "Epoch 32/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2313 - accuracy: 0.8996 - val_loss: 0.3464 - val_accuracy: 0.8492\n",
      "Epoch 33/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2274 - accuracy: 0.8980 - val_loss: 0.3451 - val_accuracy: 0.8562\n",
      "Epoch 34/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.2238 - accuracy: 0.9048 - val_loss: 0.3377 - val_accuracy: 0.8415\n",
      "Epoch 35/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.2198 - accuracy: 0.9071 - val_loss: 0.3456 - val_accuracy: 0.8508\n",
      "Epoch 36/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.2158 - accuracy: 0.9073 - val_loss: 0.3606 - val_accuracy: 0.8492\n",
      "Epoch 37/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9136 - val_loss: 0.3385 - val_accuracy: 0.8608\n",
      "Epoch 38/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.2107 - accuracy: 0.9111 - val_loss: 0.3482 - val_accuracy: 0.8531\n",
      "Epoch 39/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.9088 - val_loss: 0.3512 - val_accuracy: 0.8554\n",
      "Epoch 40/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.2008 - accuracy: 0.9163 - val_loss: 0.3415 - val_accuracy: 0.8546\n",
      "Epoch 41/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1987 - accuracy: 0.9151 - val_loss: 0.3508 - val_accuracy: 0.8538\n",
      "Epoch 42/50\n",
      "520/520 [==============================] - 1s 2ms/step - loss: 0.1936 - accuracy: 0.9180 - val_loss: 0.3607 - val_accuracy: 0.8431\n",
      "Epoch 43/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1943 - accuracy: 0.9200 - val_loss: 0.3623 - val_accuracy: 0.8531\n",
      "Epoch 44/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1898 - accuracy: 0.9215 - val_loss: 0.3674 - val_accuracy: 0.8462\n",
      "Epoch 45/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1853 - accuracy: 0.9221 - val_loss: 0.3514 - val_accuracy: 0.8508\n",
      "Epoch 46/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.3599 - val_accuracy: 0.8585\n",
      "Epoch 47/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1800 - accuracy: 0.9255 - val_loss: 0.3622 - val_accuracy: 0.8638\n",
      "Epoch 48/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1747 - accuracy: 0.9251 - val_loss: 0.3617 - val_accuracy: 0.8531\n",
      "Epoch 49/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1709 - accuracy: 0.9263 - val_loss: 0.3569 - val_accuracy: 0.8515\n",
      "Epoch 50/50\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1672 - accuracy: 0.9292 - val_loss: 0.3644 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb0a3b78b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Neural Network Model.\n",
    "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "nn_model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ed2fb06-1ae0-4716-a0d1-b6212b9439f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "Architecture: [32, 16]\n",
      "[[1029   19]\n",
      " [ 221   31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.90      1048\n",
      "           1       0.62      0.12      0.21       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.72      0.55      0.55      1300\n",
      "weighted avg       0.78      0.82      0.76      1300\n",
      "\n",
      "Accuracy: 0.8153846153846154\n",
      "\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Architecture: [64, 32, 16]\n",
      "[[1009   39]\n",
      " [ 193   59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      1048\n",
      "           1       0.60      0.23      0.34       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.72      0.60      0.62      1300\n",
      "weighted avg       0.79      0.82      0.79      1300\n",
      "\n",
      "Accuracy: 0.8215384615384616\n",
      "\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Architecture: [128, 64, 32]\n",
      "[[1027   21]\n",
      " [ 224   28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      1048\n",
      "           1       0.57      0.11      0.19       252\n",
      "\n",
      "    accuracy                           0.81      1300\n",
      "   macro avg       0.70      0.55      0.54      1300\n",
      "weighted avg       0.77      0.81      0.76      1300\n",
      "\n",
      "Accuracy: 0.8115384615384615\n",
      "\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Architecture: [32, 32, 32]\n",
      "[[965  83]\n",
      " [162  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      1048\n",
      "           1       0.52      0.36      0.42       252\n",
      "\n",
      "    accuracy                           0.81      1300\n",
      "   macro avg       0.69      0.64      0.66      1300\n",
      "weighted avg       0.79      0.81      0.80      1300\n",
      "\n",
      "Accuracy: 0.8115384615384615\n",
      "\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Architecture: [64, 64]\n",
      "[[990  58]\n",
      " [180  72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      1048\n",
      "           1       0.55      0.29      0.38       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.70      0.62      0.63      1300\n",
      "weighted avg       0.79      0.82      0.79      1300\n",
      "\n",
      "Accuracy: 0.816923076923077\n",
      "\n",
      "Best Architecture: [64, 32, 16]\n",
      "Best Accuracy: 0.8215384615384616\n"
     ]
    }
   ],
   "source": [
    "# Assuming X and y are your features and labels\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert y_test to a numpy array\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Define different architectures\n",
    "architectures = [\n",
    "    [32, 16],   # Two hidden layers with 32 and 16 neurons\n",
    "    [64, 32, 16],  # Three hidden layers with 64, 32, and 16 neurons\n",
    "    [128, 64, 32],  # Three hidden layers with 128, 64, and 32 neurons\n",
    "    [32, 32, 32],   # Three hidden layers with 32 neurons each\n",
    "    [64, 64],  # Two hidden layers with 64 neurons each\n",
    "]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_architecture = None\n",
    "\n",
    "for architecture in architectures:\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(architecture[0], input_dim=X_train.shape[1], activation='relu'))\n",
    "    \n",
    "    for units in architecture[1:]:\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test), verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred_nn = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    accuracy = np.mean(y_pred_nn == y_test.reshape(-1, 1))\n",
    "    \n",
    "    print(f\"Architecture: {architecture}\")\n",
    "    print(confusion_matrix(y_test, y_pred_nn))\n",
    "    print(classification_report(y_test, y_pred_nn))\n",
    "    print(f\"Accuracy: {accuracy}\\n\")\n",
    "    \n",
    "    # Save the best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_architecture = architecture\n",
    "\n",
    "print(f\"Best Architecture: {best_architecture}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08729c84-6974-4d70-9350-a08dd4824f6c",
   "metadata": {},
   "source": [
    "Best Architecture: [64, 32, 16]\n",
    "\n",
    "Best Accuracy: 0.8215384615384616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf3823b-b9a3-4ec7-bb84-dd24c482f919",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [32, 16] | Activation: relu\n",
      "[[1012   36]\n",
      " [ 199   53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      1048\n",
      "           1       0.60      0.21      0.31       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.72      0.59      0.60      1300\n",
      "weighted avg       0.79      0.82      0.78      1300\n",
      "\n",
      "Accuracy: 0.8192307692307692\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [32, 16] | Activation: tanh\n",
      "[[1021   27]\n",
      " [ 212   40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90      1048\n",
      "           1       0.60      0.16      0.25       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.71      0.57      0.57      1300\n",
      "weighted avg       0.78      0.82      0.77      1300\n",
      "\n",
      "Accuracy: 0.8161538461538461\n",
      "\n",
      "41/41 [==============================] - 0s 946us/step\n",
      "Architecture: [32, 16] | Activation: sigmoid\n",
      "[[985  63]\n",
      " [166  86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      1048\n",
      "           1       0.58      0.34      0.43       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.72      0.64      0.66      1300\n",
      "weighted avg       0.80      0.82      0.81      1300\n",
      "\n",
      "Accuracy: 0.8238461538461539\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [64, 32, 16] | Activation: relu\n",
      "[[962  86]\n",
      " [144 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      1048\n",
      "           1       0.56      0.43      0.48       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.71      0.67      0.69      1300\n",
      "weighted avg       0.81      0.82      0.81      1300\n",
      "\n",
      "Accuracy: 0.823076923076923\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [64, 32, 16] | Activation: tanh\n",
      "[[1023   25]\n",
      " [ 204   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90      1048\n",
      "           1       0.66      0.19      0.30       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.75      0.58      0.60      1300\n",
      "weighted avg       0.80      0.82      0.78      1300\n",
      "\n",
      "Accuracy: 0.8238461538461539\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [64, 32, 16] | Activation: sigmoid\n",
      "[[1010   38]\n",
      " [ 192   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      1048\n",
      "           1       0.61      0.24      0.34       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.73      0.60      0.62      1300\n",
      "weighted avg       0.80      0.82      0.79      1300\n",
      "\n",
      "Accuracy: 0.823076923076923\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [128, 64, 32] | Activation: relu\n",
      "[[962  86]\n",
      " [156  96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      1048\n",
      "           1       0.53      0.38      0.44       252\n",
      "\n",
      "    accuracy                           0.81      1300\n",
      "   macro avg       0.69      0.65      0.67      1300\n",
      "weighted avg       0.80      0.81      0.80      1300\n",
      "\n",
      "Accuracy: 0.8138461538461539\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [128, 64, 32] | Activation: tanh\n",
      "[[1040    8]\n",
      " [ 234   18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      1048\n",
      "           1       0.69      0.07      0.13       252\n",
      "\n",
      "    accuracy                           0.81      1300\n",
      "   macro avg       0.75      0.53      0.51      1300\n",
      "weighted avg       0.79      0.81      0.75      1300\n",
      "\n",
      "Accuracy: 0.8138461538461539\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [128, 64, 32] | Activation: sigmoid\n",
      "[[1020   28]\n",
      " [ 209   43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90      1048\n",
      "           1       0.61      0.17      0.27       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.72      0.57      0.58      1300\n",
      "weighted avg       0.79      0.82      0.77      1300\n",
      "\n",
      "Accuracy: 0.8176923076923077\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [32, 32, 32] | Activation: relu\n",
      "[[996  52]\n",
      " [172  80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      1048\n",
      "           1       0.61      0.32      0.42       252\n",
      "\n",
      "    accuracy                           0.83      1300\n",
      "   macro avg       0.73      0.63      0.66      1300\n",
      "weighted avg       0.80      0.83      0.81      1300\n",
      "\n",
      "Accuracy: 0.8276923076923077\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [32, 32, 32] | Activation: tanh\n",
      "[[832 216]\n",
      " [ 86 166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85      1048\n",
      "           1       0.43      0.66      0.52       252\n",
      "\n",
      "    accuracy                           0.77      1300\n",
      "   macro avg       0.67      0.73      0.69      1300\n",
      "weighted avg       0.81      0.77      0.78      1300\n",
      "\n",
      "Accuracy: 0.7676923076923077\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [32, 32, 32] | Activation: sigmoid\n",
      "[[989  59]\n",
      " [175  77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      1048\n",
      "           1       0.57      0.31      0.40       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.71      0.62      0.65      1300\n",
      "weighted avg       0.79      0.82      0.80      1300\n",
      "\n",
      "Accuracy: 0.82\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [64, 64] | Activation: relu\n",
      "[[986  62]\n",
      " [179  73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      1048\n",
      "           1       0.54      0.29      0.38       252\n",
      "\n",
      "    accuracy                           0.81      1300\n",
      "   macro avg       0.69      0.62      0.63      1300\n",
      "weighted avg       0.79      0.81      0.79      1300\n",
      "\n",
      "Accuracy: 0.8146153846153846\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [64, 64] | Activation: tanh\n",
      "[[1027   21]\n",
      " [ 207   45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90      1048\n",
      "           1       0.68      0.18      0.28       252\n",
      "\n",
      "    accuracy                           0.82      1300\n",
      "   macro avg       0.76      0.58      0.59      1300\n",
      "weighted avg       0.80      0.82      0.78      1300\n",
      "\n",
      "Accuracy: 0.8246153846153846\n",
      "\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Architecture: [64, 64] | Activation: sigmoid\n",
      "[[1001   47]\n",
      " [ 174   78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      1048\n",
      "           1       0.62      0.31      0.41       252\n",
      "\n",
      "    accuracy                           0.83      1300\n",
      "   macro avg       0.74      0.63      0.66      1300\n",
      "weighted avg       0.81      0.83      0.81      1300\n",
      "\n",
      "Accuracy: 0.83\n",
      "\n",
      "Best Architecture: [64, 64]\n",
      "Best Activation Function: sigmoid\n",
      "Best Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Assuming X and y are your features and labels\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert y_test to a numpy array\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Define different architectures\n",
    "architectures = [\n",
    "    [32, 16],   # Two hidden layers with 32 and 16 neurons\n",
    "    [64, 32, 16],  # Three hidden layers with 64, 32, and 16 neurons\n",
    "    [128, 64, 32],  # Three hidden layers with 128, 64, and 32 neurons\n",
    "    [32, 32, 32],   # Three hidden layers with 32 neurons each\n",
    "    [64, 64],  # Two hidden layers with 64 neurons each\n",
    "]\n",
    "\n",
    "# Define different activation functions\n",
    "activation_functions = ['relu', 'tanh', 'sigmoid']\n",
    "\n",
    "# Function to create model\n",
    "def create_model(architecture, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(architecture[0], input_dim=X_train.shape[1], activation=activation))\n",
    "    \n",
    "    for units in architecture[1:]:\n",
    "        model.add(Dense(units, activation=activation))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_architecture = None\n",
    "best_activation = None\n",
    "\n",
    "for architecture in architectures:\n",
    "    for activation in activation_functions:\n",
    "        # Create the model\n",
    "        model = create_model(architecture, activation)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test), verbose=0)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred_nn = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "        accuracy = np.mean(y_pred_nn == y_test.reshape(-1, 1))\n",
    "        \n",
    "        print(f\"Architecture: {architecture} | Activation: {activation}\")\n",
    "        print(confusion_matrix(y_test, y_pred_nn))\n",
    "        print(classification_report(y_test, y_pred_nn))\n",
    "        print(f\"Accuracy: {accuracy}\\n\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            best_architecture = architecture\n",
    "            best_activation = activation\n",
    "\n",
    "print(f\"Best Architecture: {best_architecture}\")\n",
    "print(f\"Best Activation Function: {best_activation}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6152329-a1f5-4412-9ea7-9c789a9b79fd",
   "metadata": {},
   "source": [
    "Best Architecture: [64, 64]\n",
    "Best Activation Function: sigmoid\n",
    "Best Accuracy: 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697b701-0a11-4f65-9371-07069a937f39",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [32, 16] | Activation: relu\n",
    "[[1012   36]\n",
    " [ 199   53]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.97      0.90      1048\n",
    "           1       0.60      0.21      0.31       252\n",
    "\n",
    "    accuracy                           0.82      1300\n",
    "   macro avg       0.72      0.59      0.60      1300\n",
    "weighted avg       0.79      0.82      0.78      1300\n",
    "\n",
    "Accuracy: 0.8192307692307692\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [32, 16] | Activation: tanh\n",
    "[[1021   27]\n",
    " [ 212   40]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.97      0.90      1048\n",
    "           1       0.60      0.16      0.25       252\n",
    "\n",
    "    accuracy                           0.82      1300\n",
    "   macro avg       0.71      0.57      0.57      1300\n",
    "weighted avg       0.78      0.82      0.77      1300\n",
    "\n",
    "Accuracy: 0.8161538461538461\n",
    "\n",
    "41/41 [==============================] - 0s 946us/step\n",
    "Architecture: [32, 16] | Activation: sigmoid\n",
    "[[985  63]\n",
    " [166  86]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.94      0.90      1048\n",
    "           1       0.58      0.34      0.43       252\n",
    "\n",
    "    accuracy                           0.82      1300\n",
    "   macro avg       0.72      0.64      0.66      1300\n",
    "weighted avg       0.80      0.82      0.81      1300\n",
    "\n",
    "Accuracy: 0.8238461538461539\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [64, 32, 16] | Activation: relu\n",
    "[[962  86]\n",
    " [144 108]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.92      0.89      1048\n",
    "           1       0.56      0.43      0.48       252\n",
    "\n",
    "    accuracy                           0.82      1300\n",
    "   macro avg       0.71      0.67      0.69      1300\n",
    "weighted avg       0.81      0.82      0.81      1300\n",
    "\n",
    "Accuracy: 0.823076923076923\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [64, 32, 16] | Activation: tanh\n",
    "[[1023   25]\n",
    " [ 204   48]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.98      0.90      1048\n",
    "           1       0.66      0.19      0.30       252\n",
    "\n",
    "    accuracy                           0.82      1300\n",
    "   macro avg       0.75      0.58      0.60      1300\n",
    "weighted avg       0.80      0.82      0.78      1300\n",
    "\n",
    "Accuracy: 0.8238461538461539\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [64, 32, 16] | Activation: sigmoid\n",
    "[[1010   38]\n",
    " [ 192   60]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.96      0.90      1048\n",
    "           1       0.61      0.24      0.34       252\n",
    "\n",
    "    accuracy                           0.82      1300\n",
    "   macro avg       0.73      0.60      0.62      1300\n",
    "weighted avg       0.80      0.82      0.79      1300\n",
    "\n",
    "Accuracy: 0.823076923076923\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [128, 64, 32] | Activation: relu\n",
    "[[962  86]\n",
    " [156  96]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.92      0.89      1048\n",
    "           1       0.53      0.38      0.44       252\n",
    "\n",
    "    accuracy                           0.81      1300\n",
    "   macro avg       0.69      0.65      0.67      1300\n",
    "weighted avg       0.80      0.81      0.80      1300\n",
    "\n",
    "Accuracy: 0.8138461538461539\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [128, 64, 32] | Activation: tanh\n",
    "[[1040    8]\n",
    " [ 234   18]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.99      0.90      1048\n",
    "           1       0.69      0.07      0.13       252\n",
    "\n",
    "    accuracy                           0.81      1300\n",
    "   macro avg       0.75      0.53      0.51      1300\n",
    "weighted avg       0.79      0.81      0.75      1300\n",
    "\n",
    "Accuracy: 0.8138461538461539\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [128, 64, 32] | Activation: sigmoid\n",
    "[[1020   28]\n",
    " [ 209   43]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.97      0.90      1048\n",
    "           1       0.61      0.17      0.27       252\n",
    "\n",
    "    accuracy                           0.82      1300\n",
    "   macro avg       0.72      0.57      0.58      1300\n",
    "weighted avg       0.79      0.82      0.77      1300\n",
    "\n",
    "Accuracy: 0.8176923076923077\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [32, 32, 32] | Activation: relu\n",
    "[[996  52]\n",
    " [172  80]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.95      0.90      1048\n",
    "           1       0.61      0.32      0.42       252\n",
    "\n",
    "    accuracy                           0.83      1300\n",
    "   macro avg       0.73      0.63      0.66      1300\n",
    "weighted avg       0.80      0.83      0.81      1300\n",
    "\n",
    "Accuracy: 0.8276923076923077\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [32, 32, 32] | Activation: tanh\n",
    "[[832 216]\n",
    " [ 86 166]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.79      0.85      1048\n",
    "           1       0.43      0.66      0.52       252\n",
    "\n",
    "    accuracy                           0.77      1300\n",
    "   macro avg       0.67      0.73      0.69      1300\n",
    "weighted avg       0.81      0.77      0.78      1300\n",
    "\n",
    "Accuracy: 0.7676923076923077\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [32, 32, 32] | Activation: sigmoid\n",
    "[[989  59]\n",
    " [175  77]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.94      0.89      1048\n",
    "           1       0.57      0.31      0.40       252\n",
    "\n",
    "    accuracy                           0.82      1300\n",
    "   macro avg       0.71      0.62      0.65      1300\n",
    "weighted avg       0.79      0.82      0.80      1300\n",
    "\n",
    "Accuracy: 0.82\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [64, 64] | Activation: relu\n",
    "[[986  62]\n",
    " [179  73]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.94      0.89      1048\n",
    "           1       0.54      0.29      0.38       252\n",
    "\n",
    "    accuracy                           0.81      1300\n",
    "   macro avg       0.69      0.62      0.63      1300\n",
    "weighted avg       0.79      0.81      0.79      1300\n",
    "\n",
    "Accuracy: 0.8146153846153846\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [64, 64] | Activation: tanh\n",
    "[[1027   21]\n",
    " [ 207   45]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.98      0.90      1048\n",
    "           1       0.68      0.18      0.28       252\n",
    "\n",
    "    accuracy                           0.82      1300\n",
    "   macro avg       0.76      0.58      0.59      1300\n",
    "weighted avg       0.80      0.82      0.78      1300\n",
    "\n",
    "Accuracy: 0.8246153846153846\n",
    "\n",
    "41/41 [==============================] - 0s 1ms/step\n",
    "Architecture: [64, 64] | Activation: sigmoid\n",
    "[[1001   47]\n",
    " [ 174   78]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.96      0.90      1048\n",
    "           1       0.62      0.31      0.41       252\n",
    "\n",
    "    accuracy                           0.83      1300\n",
    "   macro avg       0.74      0.63      0.66      1300\n",
    "weighted avg       0.81      0.83      0.81      1300\n",
    "\n",
    "Accuracy: 0.83\n",
    "\n",
    "Best Architecture: [64, 64]\n",
    "Best Activation Function: sigmoid\n",
    "Best Accuracy: 0.83\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8de32d-54cb-4258-96ed-ef35692e7fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
